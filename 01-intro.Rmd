# Introduction {#intro}

You can label chapter and section titles using `{#label}` after them, e.g., we can reference Chapter \@ref(intro). If you do not manually label them, there will be automatic labels anyway, e.g., Chapter \@ref(methods).

Figures and tables with captions will be placed in `figure` and `table` environments, respectively.

```{r nice-fig, fig.cap='Here is a nice figure!', out.width='80%', fig.asp=.75, fig.align='center'}
par(mar = c(4, 4, .1, .1))
plot(pressure, type = 'b', pch = 19)
```

Reference a figure by its code chunk label with the `fig:` prefix, e.g., see Figure \@ref(fig:nice-fig). Similarly, you can reference tables generated from `knitr::kable()`, e.g., see Table \@ref(tab:nice-tab).

```{r nice-tab, tidy=FALSE}
knitr::kable(
  head(iris, 20), caption = 'Here is a nice table!',
  booktabs = TRUE
)
```

You can write citations, too. For example, we are using the **bookdown** package [@R-bookdown] in this sample book, which was built on top of R Markdown and **knitr** [@xie2015].



# Introduction {#intro}
This chapter introduces the dataset that we will be using and cleaning the data for the next chapters in this books. 

## Dataset 
We will be using the _Wave 6_ of the [World Values Survey](https://www.worldvaluessurvey.org/WVSDocumentationWV6.jsp) for this project. The data for this survey was collected between 2010 and 2014. 
\n 
We will be using the following libraries for data cleaning 
```{r}
library(tidyverse)
library(reactable)
```

Let's first load the data 
```{r}
load("~/Desktop/bookdown-demo-main/data/WV6_Data_R_v20201117.rdata")
data_raw <- WV6_Data_R_v20201117
```

```{r eval=FALSE}
#code used for looking at the data
dplyr::glimpse(data_raw)

#View(data_raw)
```


## Functions
This chunk will involve building functions for executing several tasks and operations. I will provide explanation about each function in the comments. 
```{r}
#Function 1
  #Call and pring the value for a specific country 

 cntry_n <- function(country_code) {
   data_raw %>% 
     count(C_COW_ALPHA) %>% 
     filter(C_COW_ALPHA == {{country_code}}) 
 }

#Function 2 
  #ncol and nrow at the same time

length_CnR <- function(data){  
  n_col <- ncol(data)
  n_row <- nrow(data)
  return(tibble(n_col, n_row))
}
```


Three countries considered to be least similar on aspects such as language, social structures and values will be retained. Let's look at the sampel sizes for each country. 

```{r}
data_raw %>% 
  count(C_COW_ALPHA) %>% 
  arrange(desc(n)) %>% 
  
  reactable(
    defaultColDef = colDef(
    cell = function(value) format(value, nsmall = 1),
    align = "center",
    minWidth = 70,
    headerStyle = list(background = "#f7f7f8")
    ),
  
    
    columns = list(
    C_COW_ALPHA = colDef(name = "Country Code"),
    n = colDef(name = "Sample size (n)")
    ),
    
  bordered = TRUE,
  highlight = TRUE
  )
```

\n
Three countries for this analysis include - The United States of America (USA) ( _n_ = `r printnum(cntry_n("USA")$n)`), India (IND) ( _n_ = `r printnum(cntry_n("IND")$n)`) and Nigeria (NIG) ( _n_ = `r printnum(cntry_n("NIG")$n)`)
\n
Let's take a closer look at the data in these countries. 
```{r}
 data = data_raw %>% 
   filter(C_COW_ALPHA %in% c("USA","IND","NIG")) %>% 
  rename("country" = C_COW_ALPHA) %>% 
  dplyr::select(country, V4:V9, V12:V22, V45:V56, V70:V79, V95:V146, -V144, V153:V160J, V192:V216, V228A:V228K) %>% 
  #remove cols which have all NA's
  janitor::remove_empty(which = "cols") %>% 
  #remove cols which have 20% or more missing data (NA)
  purrr::discard(~sum(is.na(.x))/length(.x)* 100 >=20) %>% 
  #impute the missing values with 
  mutate_all(~ifelse(is.na(.x), mean(.x, na.rm = TRUE), .x)) %>% 
  remove_rownames()


# data %>% 
#   count(C_COW_ALPHA)
# length_CnR(data)   
# table(is.na(data))
# names(data)
# names(data_raw)

#View(data)

 
```



```{r}
#Transpose data 
data_t <- data %>% 
  mutate(ind = paste0("p", 1:nrow(data))) %>% 
   dplyr::select(ind, everything(), -C_COW_ALPHA) %>% 
  t %>% as.data.frame() %>% janitor::row_to_names(1) %>% 
  mutate_all(funs(as.numeric(as.character(.))))

colnames(data_t)  
  
colnames(data)
rownames(data)
View(data)
length_CnR(data)
```

# Cluster analysis 

## Data preparation 

```{r}
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
 data <- data[,-caret::nearZeroVar(data)] #remove columns with near zero variance
 data <- data %>% select(-country) %>% scale
```

## K-means Clustering 
This type of Clustering involves minimizing the within cluster variation. Hartigan and Wong(1979) provided the following algorithm for K-means Clustering 

$$W(C_k) =  \sum_{x_1 \in C_k}(x_i-Î¼_k)^2$$

